START

  1. Define Constants  
      CONFIG_FILE: Path to the configuration JSON file
      OUTPUT_FILE: Path to the output CSV file
      USER_AGENT: UserAgent string to mimic a browser

  2. Define Function safe_get(element, selector, attribute)  
     INPUT: element (HTML element), selector (CSS selector), attribute (default "text")
     OUTPUT: text or attribute value of the HTML element or empty string if not found
     
      Find the first matching element using the selector
      If the element exists:
          If the attribute is "text", return the text content of the element
          Otherwise, return the specified attribute value (e.g., href for links)
      If element doesn't exist, return an empty string

  3. Define Function get_search_url(engine, query, page)  
     INPUT: engine (search engine name), query (search query string), page (page number)
     OUTPUT: Constructed search URL for the specified search engine
     
      URL format based on search engine:
          For Google: Construct Google News search URL with query and page
          For Bing: Construct Bing News search URL with query and page
          For Yahoo: Construct Yahoo News search URL with query and page
      Return the URL

  4. Define Function scrape_results()
      Open CONFIG_FILE and load configuration (companies, keywords, pages)
      Open OUTPUT_FILE and prepare to write CSV with headers: Search String, Search Engine, Link, Title, Time stamp, Media name
     
     FOR each company in companies list:
         FOR each keyword in keywords list:
              Construct the search string: "company keyword"
             
             FOR each search engine in ["google", "bing", "yahoo"]:
                 FOR each page from 1 to total pages:
                      Construct the search URL using get_search_url(engine, search_string, page)
                     
                     TRY:
                          Send HTTP request to the search URL with the specified USER_AGENT
                          If the response is successful, parse the page content with BeautifulSoup
                         
                          Extract article data based on the search engine:
                              For Google: Select and extract title, link, timestamp, and media
                              For Bing: Select and extract title, link, timestamp, and media
                              For Yahoo: Select and extract title, link, timestamp, and media
                         
                          Write the extracted data to the CSV file

                     EXCEPT (if error occurs):
                          Print error message (e.g., for network issues or parsing errors)
                          Skip to the next page or search engine

  5. Main Execution Block
      Call scrape_results() to start the scraping process
      After completion, print "Scraping completed! Results saved to OUTPUT_FILE"

END
